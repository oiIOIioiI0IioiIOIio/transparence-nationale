#!/usr/bin/env python3
"""
Script de g√©n√©ration des donn√©es des √©lus fran√ßais.
Sources: HATVP OpenData CSV, API Assembl√©e Nationale
G√©n√®re: public/data/elus.json
"""

import argparse
import csv
import io
import json
import os
import sys
import time
import unicodedata
import urllib.request
import urllib.parse
import urllib.error

# Chemins relatifs depuis la racine du projet (calcul√©s √† partir de __file__)
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
DEFAULT_OUTPUT = os.path.join(PROJECT_ROOT, "public", "data", "elus.json")

HATVP_CSV_URL = "https://www.hatvp.fr/livraison/opendata/liste.csv"
AN_API_BASE = "https://data.assemblee-nationale.fr/api/v2/"

# Indemnit√©s parlementaires de base
INDEMNITE_DEPUTE = 85296
INDEMNITE_SENATEUR = 87480

HEADERS = {
    "User-Agent": "TransparenceNationale/1.0 (https://github.com/transparence-nationale)"
}


def parse_args():
    parser = argparse.ArgumentParser(description="G√©n√®re public/data/elus.json depuis HATVP + API AN.")
    parser.add_argument(
        "--output",
        default=DEFAULT_OUTPUT,
        help=f"Chemin de sortie (d√©faut : {DEFAULT_OUTPUT})",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Limiter le nombre d'√©lus g√©n√©r√©s (utile pour les tests)",
    )
    return parser.parse_args()


def slugify(text):
    """Convertir un nom en slug ASCII minuscule."""
    text = text.lower().strip()
    text = unicodedata.normalize("NFD", text)
    text = "".join(c for c in text if unicodedata.category(c) != "Mn")
    text = text.replace(" ", "-").replace("'", "-").replace("'", "-")
    # Supprimer les caract√®res non alphanum√©riques (sauf tiret)
    text = "".join(c for c in text if c.isalnum() or c == "-")
    # Fusionner les tirets multiples
    while "--" in text:
        text = text.replace("--", "-")
    return text.strip("-")


def http_get(url, timeout=20):
    """Effectuer une requ√™te GET et retourner le contenu brut, ou None."""
    req = urllib.request.Request(url, headers=HEADERS)
    try:
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            if resp.status == 200:
                return resp.read()
    except urllib.error.HTTPError as exc:
        print(f"  ‚ö† HTTP {exc.code} pour {url}")
    except Exception as exc:
        print(f"  ‚ö† Erreur r√©seau ({url}) : {exc}")
    return None


def fetch_hatvp_csv():
    """T√©l√©charger et parser le CSV HATVP."""
    print(f"üîÑ T√©l√©chargement du CSV HATVP‚Ä¶")
    raw = http_get(HATVP_CSV_URL)
    if not raw:
        print("‚úó Impossible de t√©l√©charger le CSV HATVP")
        return []

    # Le CSV peut √™tre encod√© en UTF-8 ou latin-1
    for encoding in ("utf-8-sig", "latin-1", "utf-8"):
        try:
            text = raw.decode(encoding)
            break
        except UnicodeDecodeError:
            continue
    else:
        print("‚úó Impossible de d√©coder le CSV HATVP")
        return []

    reader = csv.DictReader(io.StringIO(text), delimiter=";")
    rows = list(reader)
    print(f"‚úì {len(rows)} d√©clarants HATVP r√©cup√©r√©s")
    return rows


def fetch_an_deputes():
    """R√©cup√©rer les d√©put√©s depuis l'API open data de l'Assembl√©e Nationale."""
    print("üîÑ R√©cup√©ration des d√©put√©s depuis l'API Assembl√©e Nationale‚Ä¶")
    deputes = {}
    url = f"{AN_API_BASE}deputes/json"
    data = http_get(url)
    if not data:
        print("  ‚ö† API AN indisponible, enrichissement id_an ignor√©")
        return deputes

    try:
        result = json.loads(data.decode("utf-8"))
        # Structure possible : {"deputes": [{"depute": {...}}, ...]}
        items = result.get("deputes", [])
        for item in items:
            dep = item.get("depute", item)
            prenom = dep.get("prenom", "") or dep.get("prenom_usuel", "")
            nom = dep.get("nom", "") or dep.get("nom_de_famille", "")
            uid = dep.get("uid", {})
            id_an = uid if isinstance(uid, str) else uid.get("#text", "")
            circ = dep.get("mandats", {})
            region = ""
            if isinstance(circ, dict):
                for mandat in circ.get("mandat", []):
                    if isinstance(mandat, dict) and mandat.get("typeOrgane") == "CIRCONSCRIPTION":
                        region = mandat.get("libelle", "")
                        break

            if prenom and nom:
                key = slugify(f"{prenom} {nom}")
                deputes[key] = {
                    "id_an": id_an,
                    "region": region,
                }
        print(f"‚úì {len(deputes)} d√©put√©s r√©cup√©r√©s depuis l'API AN")
    except Exception as exc:
        print(f"  ‚ö† Parsing API AN : {exc}")

    return deputes


def hatvp_row_to_elu(row, an_map):
    """Convertir une ligne CSV HATVP en structure √©lu."""
    # Les colonnes peuvent varier selon la version du CSV
    nom = (row.get("nom") or row.get("Nom") or "").strip()
    prenom = (row.get("prenom") or row.get("Pr√©nom") or row.get("prenom_usuel") or "").strip()
    if not nom or not prenom:
        return None

    elu_id = slugify(f"{prenom} {nom}")
    key = elu_id  # m√™me cl√© dans an_map

    an_info = an_map.get(key, {})
    id_an = an_info.get("id_an", "")
    region = an_info.get("region", "")

    # Fonctions / mandats
    fonction_raw = (
        row.get("fonction") or row.get("Fonction") or
        row.get("mandat") or row.get("Mandat") or ""
    ).strip()

    # D√©terminer le type d'√©lu et le revenu
    revenus = INDEMNITE_DEPUTE
    mandats = []
    fonction = fonction_raw or "√âlu(e)"
    if "s√©nateur" in fonction.lower() or "s√©natrice" in fonction.lower():
        revenus = INDEMNITE_SENATEUR
        mandats = ["S√©nateur(trice)"]
        if not fonction_raw:
            fonction = "S√©nateur(trice)"
    elif "d√©put√©" in fonction.lower() or "d√©put√©e" in fonction.lower():
        mandats = ["D√©put√©(e)"]
        if region and "de" not in fonction.lower():
            fonction = f"D√©put√©(e) de {region}"
    else:
        mandats = [fonction_raw] if fonction_raw else ["√âlu(e)"]

    # Donn√©es patrimoniales
    patrimoine = 0
    immobilier = 0
    placements = 0
    patrimoine_source = "non_disponible"

    def parse_amount(val):
        if not val:
            return 0
        val = val.strip().replace(" ", "").replace(",", ".").replace("‚Ç¨", "")
        try:
            return int(float(val))
        except (ValueError, TypeError):
            return 0

    pat_val = (
        row.get("total_patrimoine") or row.get("patrimoine_total") or
        row.get("Patrimoine total") or row.get("montant_total") or ""
    )
    if pat_val:
        patrimoine = parse_amount(pat_val)
        patrimoine_source = "hatvp"

    immo_val = (
        row.get("total_immobilier") or row.get("immobilier") or
        row.get("Immobilier") or ""
    )
    if immo_val:
        immobilier = parse_amount(immo_val)

    place_val = (
        row.get("total_placements") or row.get("placements") or
        row.get("Placements") or ""
    )
    if place_val:
        placements = parse_amount(place_val)

    # Parti
    parti = (row.get("parti") or row.get("Parti") or row.get("groupe") or "").strip()

    # URL HATVP
    hatvp_url = f"https://www.hatvp.fr/fiche-nominative/?declarant={nom}-{prenom}"
    an_url = f"https://www.assemblee-nationale.fr/dyn/deputes/{id_an}" if id_an else ""

    elu = {
        "id": elu_id,
        "nom": nom,
        "prenom": prenom,
        "fonction": fonction,
        "region": region,
        "revenus": revenus,
        "patrimoine": patrimoine,
        "immobilier": immobilier,
        "placements": placements,
        "patrimoine_source": patrimoine_source,
        "mandats": mandats,
        "parti": parti,
        "photo": "/photos/placeholder.jpg",
        "liens": {
            "assemblee": an_url,
            "hatvp": hatvp_url,
            "wikipedia": "",
        },
    }

    if id_an:
        elu["id_an"] = id_an

    return elu


def merge_with_existing(new_elus, existing_elus):
    """
    Fusionner les nouveaux √©lus avec les existants.
    Les entr√©es existantes sont enrichies, pas √©cras√©es.
    """
    existing_map = {e["id"]: e for e in existing_elus}

    for elu in new_elus:
        eid = elu["id"]
        if eid in existing_map:
            existing = existing_map[eid]
            # Enrichir les champs manquants ou vides
            for key, value in elu.items():
                if key not in existing or not existing[key]:
                    existing[key] = value
                elif key in ("liens",) and isinstance(value, dict):
                    for lk, lv in value.items():
                        if not existing[key].get(lk):
                            existing[key][lk] = lv
        else:
            existing_map[eid] = elu

    return list(existing_map.values())


def main():
    args = parse_args()

    print("=" * 60)
    print("üó≥Ô∏è  G√âN√âRATEUR DE DONN√âES √âLUS FRAN√áAIS")
    print("=" * 60)

    # Charger les donn√©es existantes
    existing_elus = []
    if os.path.exists(args.output):
        try:
            with open(args.output, "r", encoding="utf-8") as f:
                existing_elus = json.load(f)
            print(f"‚úì {len(existing_elus)} √©lus existants charg√©s depuis {args.output}")
        except Exception as exc:
            print(f"‚ö† Impossible de charger {args.output} : {exc}")

    # R√©cup√©rer les donn√©es
    hatvp_rows = fetch_hatvp_csv()
    time.sleep(0.2)
    an_map = fetch_an_deputes()

    # Convertir les lignes HATVP en √©lus
    new_elus = []
    seen_ids = set()
    for row in hatvp_rows:
        elu = hatvp_row_to_elu(row, an_map)
        if elu and elu["id"] not in seen_ids:
            seen_ids.add(elu["id"])
            new_elus.append(elu)

    print(f"‚úì {len(new_elus)} √©lus convertis depuis HATVP")

    # Fusionner avec les donn√©es existantes
    merged = merge_with_existing(new_elus, existing_elus)

    # Trier par nom
    merged.sort(key=lambda e: (e.get("nom", ""), e.get("prenom", "")))

    # Appliquer la limite si demand√©e
    if args.limit:
        merged = merged[: args.limit]

    # S'assurer que le r√©pertoire de sortie existe
    os.makedirs(os.path.dirname(args.output), exist_ok=True)

    # Sauvegarder
    with open(args.output, "w", encoding="utf-8") as f:
        json.dump(merged, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 60)
    print(f"‚úì {len(merged)} √©lus g√©n√©r√©s ‚Üí {args.output}")
    print("=" * 60)


if __name__ == "__main__":
    main()
